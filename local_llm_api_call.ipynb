{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOCxI/+MmU7+jF1eWzWhRBM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/envererguven/langchain-rag-tutorial/blob/main/local_llm_api_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oakZrhLg2wmp"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "full_response = []\n",
        "full_response = []\n",
        "prompt = \"\"\"\n",
        "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
        "This is the recommended activity: {relevant_document}\n",
        "The user input is: {user_input}\n",
        "Compile a recommendation to the user based on the recommended activity and the user input.\n",
        "\"\"\"\n",
        "\n",
        "url = 'http://localhost:11434/api/generate'\n",
        "\n",
        "# Add placeholders for user_input and relevant_document\n",
        "user_input = \"What should I do today?\"\n",
        "relevant_document = \"Go for a walk in the park.\"\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"model\": \"llama2\",\n",
        "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
        "}\n",
        "\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "\n",
        "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
        "\n",
        "\n",
        "try:\n",
        "    for line in response.iter_lines():\n",
        "        # filter out keep-alive new lines\n",
        "        if line:\n",
        "            decoded_line = json.loads(line.decode('utf-8'))\n",
        "            # print(decoded_line['response'])  # uncomment to results, token by token\n",
        "            full_response.append(decoded_line['response'])\n",
        "finally:\n",
        "    response.close()\n",
        "\n",
        "\n",
        "print(''.join(full_response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7349e3"
      },
      "source": [
        "# Task\n",
        "Install Ollama and the Llama2 model in the Colab environment and explain how to run the Llama2 model locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7bb9078"
      },
      "source": [
        "## Install ollama\n",
        "\n",
        "### Subtask:\n",
        "Install Ollama in the Colab environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6e6f067"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute a bash command to download the Ollama installation script.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb4537ff"
      },
      "source": [
        "!curl -fsSL https://ollama.com/install.sh -o install-ollama.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a74ce206"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the downloaded script to install Ollama.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "674a88c9"
      },
      "source": [
        "!bash install-ollama.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a287c6dc"
      },
      "source": [
        "## Pull llama2 model\n",
        "\n",
        "### Subtask:\n",
        "Use Ollama to pull the Llama2 model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c37a332"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute a shell command to pull the 'llama2' model using the `ollama pull` command and observe the output to verify the download.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48ca50a2"
      },
      "source": [
        "!ollama pull llama2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0cd5958"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the Ollama server was not running. Execute a shell command to start the Ollama server in the background and then pull the llama2 model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce7b2dea"
      },
      "source": [
        "!ollama serve &\n",
        "!ollama pull llama2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}